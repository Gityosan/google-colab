{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBSZfJpPNW4C",
        "outputId": "f4bcf200-8f1e-4026-c9a7-ef08e1b946e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 4.1 MB/s \n",
            "\u001b[?25hCollecting ipadic\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.4 MB 25.8 MB/s \n",
            "\u001b[?25hCollecting fugashi\n",
            "  Downloading fugashi-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615 kB)\n",
            "\u001b[K     |████████████████████████████████| 615 kB 69.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 81.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 53.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: ipadic\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556723 sha256=ed3c43e8a14090fb6e744eb45eca4b1ab52f3e080870eaf3e887f29e5f4bf585\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/b7/f5/a21e68db846eedcd00d69e37d60bab3f68eb20b1d99cdff652\n",
            "Successfully built ipadic\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, ipadic, fugashi\n",
            "Successfully installed fugashi-1.2.1 huggingface-hub-0.11.1 ipadic-1.0.0 tokenizers-0.13.2 transformers-4.25.1\n",
            "Python 3.8.16\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers ipadic fugashi\n",
        "!python -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKuRtNx-bJIF"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from transformers import BertJapaneseTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hh5jjwZkrgPJ"
      },
      "outputs": [],
      "source": [
        "# 関数群\n",
        "# 前処理\n",
        "def preprocessing(text):\n",
        "    # ストップワードを定義\n",
        "    with open(\"Japanese.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        stop_words = set([w.strip() for w in f] + [\"する\", \"なる\", \"いる\", \"ある\"])\n",
        "    text = re.sub(r\"http\\S+\", \"\", text)\n",
        "    text = re.sub(r\"@[w/:%#$&?()~.=+-…]+[:]? \", \"\", text)\n",
        "    text = re.sub(r\"(^RT )\", \"\", text)\n",
        "    text = text.lower()  # 小文字化\n",
        "    text = re.sub(\"\\r\", \"\", text)  # \\r\\nをdelete\n",
        "    text = re.sub(\"\\n\", \"\", text)  # \\r\\nをdelete\n",
        "    text = re.sub(r\"\\d+\", \"\", text)  # 数字列をdelete\n",
        "    ZEN = \"\".join(chr(0xFF01 + i) for i in range(94))  # 全角記号一覧\n",
        "    HAN = \"\".join(chr(0x21 + i) for i in range(94))  # 半角記号一覧\n",
        "    ETC = \"\".join(chr(0x3000 + i) for i in range(30))  # その他主要そうな記号\n",
        "    text = text.translate(str.maketrans(ZEN, HAN))  # 全角記号を半角記号に置換\n",
        "    FIXED_HAN = re.sub(r\"[\\w]+\", \"\", HAN)\n",
        "    return re.sub(\"[\" + \"~\" + \"*\" + \"＊\" + ETC + FIXED_HAN + \"]\", \" \", text)  # 記号を消す\n",
        "\n",
        "\n",
        "# JSONからdf作成\n",
        "def JSONtoDF(path):\n",
        "    with open(path) as f:\n",
        "        j = json.load(f)\n",
        "        return pd.json_normalize(data=j[\"data\"]).drop(\n",
        "            [\"created_at\", \"edit_history_tweet_ids\"], axis=1\n",
        "        )\n",
        "\n",
        "\n",
        "def prepareCorpus(path_list):\n",
        "    res = pd.DataFrame()\n",
        "    for path in path_list:\n",
        "        df = JSONtoDF(path)\n",
        "        df[\"preprocessedText\"] = [preprocessing(text) for text in df[\"text\"]]\n",
        "        res = pd.concat([res, df])\n",
        "    return res.reset_index(drop=True)\n",
        "\n",
        "\n",
        "def get_context(token_ids, target_position, sequence_length=128):\n",
        "    \"\"\"\n",
        "    Given a text containing a target word, return the sentence snippet which surrounds the target word\n",
        "    (and the target word's position in the snippet).\n",
        "\n",
        "    :param token_ids: list of token ids (for an entire line of text)\n",
        "    :param target_position: index of the target word's position in `tokens`\n",
        "    :param sequence_length: desired length for output sequence (e.g. 128, 256, 512)\n",
        "    :return: (context_ids, new_target_position)\n",
        "                context_ids: list of token ids for the output sequence\n",
        "                new_target_position: index of the target word's position in `context_ids`\n",
        "    \"\"\"\n",
        "    # -2 as [CLS] and [SEP] tokens will be added later; /2 as it's a one-sided window\n",
        "    window_size = int((sequence_length - 2) / 2)\n",
        "    context_start = max([0, target_position - window_size])\n",
        "    padding_offset = max([0, window_size - target_position])\n",
        "    padding_offset += max([0, target_position + window_size - len(token_ids)])\n",
        "    context_ids = token_ids[context_start : target_position + window_size]\n",
        "    context_ids += padding_offset * [0]\n",
        "    new_target_position = target_position - context_start\n",
        "    return context_ids, new_target_position\n",
        "\n",
        "\n",
        "def get_usage(\n",
        "    text_list=[],\n",
        "    target_word=None,\n",
        "    output_path=\"word-vectors/{}.dict\".format(random.randrange(1000, 10000)),\n",
        "    sequence_length=256,\n",
        "    buffer_size=512,\n",
        "    layer_range=(1, 14),\n",
        "):\n",
        "    if not target_word:\n",
        "        return\n",
        "    TW_token = tokenizer.encode(target_word)\n",
        "    TW_token = TW_token[1 : len(TW_token) - 1]\n",
        "    batches = []\n",
        "    surrounding_words = []\n",
        "    for text in tqdm(text_list):\n",
        "        if target_word not in text:\n",
        "            continue\n",
        "        [\n",
        "            surrounding_words.append(w)\n",
        "            for w in tokenizer.tokenize(text)\n",
        "            if w not in stop_words and w not in surrounding_words\n",
        "        ]\n",
        "        tokens = tokenizer.encode(text)\n",
        "        TW_position = (\n",
        "            tokens.index(TW_token[0])\n",
        "            if len(TW_token) > 0 and TW_token[0] in tokens\n",
        "            else None\n",
        "        )\n",
        "        if TW_position == None:\n",
        "            continue\n",
        "        # このループで取り扱っている一文に対象の単語が含まれている場合以下の処理を実行する\n",
        "        input_ids, position = get_context(tokens, TW_position, sequence_length)\n",
        "        batches.append(\n",
        "            {\n",
        "                \"word\": target_word,\n",
        "                \"position\": (position, position + len(TW_token)),\n",
        "                \"input_ids\": input_ids,\n",
        "            }\n",
        "        )\n",
        "        if len(batches) >= buffer_size:\n",
        "            break\n",
        "\n",
        "    print(\"Start model fit\")\n",
        "    usages = []\n",
        "    # すでにファイルが存在すれば続きから追記\n",
        "    if os.path.exists(output_path):\n",
        "        with open(output_path, \"rb\") as f:\n",
        "            usages = pickle.load(f)\n",
        "    else:\n",
        "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        input_ids_tensor = torch.tensor([b[\"input_ids\"] for b in batches])\n",
        "        outputs = model(input_ids_tensor, output_hidden_states=True)\n",
        "        hidden_states = [l.detach().numpy() for l in outputs[2]]\n",
        "        # outputs[2]は三次元のtensor型が13個並ぶ配列 (13, 512, 256, 768) (13, B, |s|, 768)\n",
        "        # 13(隠れ12層+最終層)×文章数×単語数×768次元になる\n",
        "\n",
        "        SW_tokens = [\n",
        "            tokenizer.encode(w) + max([0, 10 - len(tokenizer.encode(w))]) * [0]\n",
        "            for w in surrounding_words\n",
        "        ]\n",
        "        outputs = model(torch.tensor(SW_tokens), output_hidden_states=True)\n",
        "        [\n",
        "            usages.append(\n",
        "                {\n",
        "                    \"word\": w,\n",
        "                    \"vector\": np.sum(\n",
        "                        outputs.last_hidden_state.detach().numpy()[i, 0:10, :]\n",
        "                    ),\n",
        "                }\n",
        "            )\n",
        "            for i, w in enumerate(surrounding_words)\n",
        "        ]\n",
        "\n",
        "    print(\"Finish model fit: word: {} / size: {}\".format(target_word, len(batches)))\n",
        "\n",
        "    # defaultで12層すべての和をとる\n",
        "    usage_vectors = np.sum(\n",
        "        np.stack(hidden_states)[layer_range[0] : layer_range[1], :, :, :], axis=0\n",
        "    )\n",
        "\n",
        "    batch = {\"word\": \"\", \"vector\": [], \"position\": [], \"input_ids\": []}\n",
        "    for i, b in enumerate(batches):\n",
        "        b[\"vector\"] = np.sum(\n",
        "            usage_vectors[i, b[\"position\"][0] : b[\"position\"][1], :], axis=0\n",
        "        )  # 文章の分散表現\n",
        "        batch = {\n",
        "            \"word\": b[\"word\"],\n",
        "            \"vector\": np.row_stack((batch[\"vector\"], b[\"vector\"]))\n",
        "            if len(batch[\"vector\"])\n",
        "            else b[\"vector\"],\n",
        "            \"position\": batch[\"position\"] + [b[\"position\"]],\n",
        "            \"input_ids\": batch[\"input_ids\"] + [b[\"input_ids\"]],\n",
        "        }\n",
        "\n",
        "    usages.append(batch)\n",
        "    with open(output_path, \"wb\") as f:\n",
        "        pickle.dump(usages, f)\n",
        "\n",
        "\n",
        "# 未実施処理\n",
        "# - 重複Tweet削除"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_xsCuP8UdCB",
        "outputId": "3e53556f-98c9-4e44-a86b-55d252bbbc63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            " 36%|███▌      | 511/1420 [00:00<00:00, 1532.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 失笑 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 511/2587 [00:00<00:01, 1071.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 失笑 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 516/4972 [00:00<00:04, 1017.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 失笑 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4934 [00:00<00:04, 951.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 失笑 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 512/4948 [00:00<00:03, 1127.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 失笑 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 512/4906 [00:00<00:03, 1238.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 失笑 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 511/4827 [00:00<00:03, 1140.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 失笑 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4917 [00:00<00:04, 1039.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 失笑 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 511/4826 [00:00<00:04, 986.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 失笑 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 529/4849 [00:00<00:04, 953.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 失笑 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 512/4829 [00:00<00:05, 845.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 失笑 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 556/4663 [00:00<00:04, 988.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 失笑 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 514/4855 [00:00<00:04, 958.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 失笑 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 536/4406 [00:00<00:04, 901.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 失笑 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 420/420 [00:00<00:00, 1705.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なし崩し / size: 420\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 511/1550 [00:00<00:00, 1373.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なし崩し / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 513/3974 [00:00<00:04, 856.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なし崩し / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4922 [00:00<00:05, 790.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なし崩し / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 579/4843 [00:00<00:04, 915.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なし崩し / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 542/4844 [00:02<00:16, 256.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なし崩し / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 524/4918 [00:00<00:03, 1130.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なし崩し / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 516/4858 [00:00<00:04, 916.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なし崩し / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█▏        | 553/4830 [00:00<00:04, 886.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なし崩し / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 514/4825 [00:00<00:04, 873.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なし崩し / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 991/4814 [00:00<00:02, 1469.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なし崩し / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 516/4830 [00:00<00:06, 706.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なし崩し / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 516/4923 [00:00<00:05, 797.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なし崩し / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 517/4786 [00:00<00:06, 653.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なし崩し / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 80/80 [00:00<00:00, 2947.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なしくずし / size: 80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 430/430 [00:00<00:00, 680.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なしくずし / size: 430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 511/2210 [00:00<00:01, 1100.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なしくずし / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 511/2257 [00:00<00:02, 833.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なしくずし / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 514/4450 [00:00<00:05, 733.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なしくずし / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 514/4715 [00:00<00:03, 1082.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なしくずし / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 516/4813 [00:00<00:07, 602.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なしくずし / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 568/4921 [00:00<00:04, 939.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なしくずし / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 511/4847 [00:00<00:05, 864.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なしくずし / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 519/4895 [00:00<00:05, 771.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なしくずし / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 511/3016 [00:00<00:04, 580.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なしくずし / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 516/4875 [00:00<00:06, 719.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なしくずし / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 515/4904 [00:00<00:05, 786.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なしくずし / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 518/4859 [00:01<00:12, 347.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: なしくずし / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:00<00:00, 2060.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 御の字 / size: 300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██▏       | 514/2400 [00:00<00:01, 1400.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 御の字 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 511/3221 [00:00<00:02, 994.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 御の字 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4944 [00:00<00:04, 994.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 御の字 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4963 [00:00<00:04, 1057.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 御の字 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4969 [00:00<00:04, 1060.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 御の字 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 516/4953 [00:00<00:03, 1152.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 御の字 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4962 [00:00<00:04, 1058.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 御の字 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4959 [00:00<00:03, 1141.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 御の字 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 514/4785 [00:00<00:03, 1139.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 御の字 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 514/4943 [00:00<00:04, 984.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 御の字 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 527/4937 [00:00<00:04, 970.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 御の字 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 516/4864 [00:00<00:04, 930.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 御の字 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4900 [00:00<00:05, 851.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 御の字 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 511/600 [00:00<00:00, 1810.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: すべからく / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 511/3810 [00:00<00:02, 1353.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: すべからく / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 511/3859 [00:00<00:03, 988.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: すべからく / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4961 [00:00<00:04, 1105.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: すべからく / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 511/4830 [00:00<00:04, 1051.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: すべからく / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 513/4849 [00:00<00:03, 1369.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: すべからく / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 512/4879 [00:00<00:02, 1564.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: すべからく / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 512/4887 [00:00<00:03, 1366.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: すべからく / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 512/4911 [00:00<00:03, 1445.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: すべからく / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 512/4873 [00:00<00:03, 1313.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: すべからく / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 512/4912 [00:00<00:03, 1375.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: すべからく / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 548/4897 [00:00<00:03, 1252.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: すべからく / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 519/4871 [00:00<00:03, 1162.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: すべからく / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 511/4644 [00:00<00:03, 1080.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: すべからく / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [00:00<00:00, 1825.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 割愛 / size: 300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 513/2340 [00:00<00:01, 1083.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 割愛 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 512/4825 [00:00<00:04, 884.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 割愛 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 513/4964 [00:00<00:05, 812.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 割愛 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 516/4914 [00:00<00:05, 843.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 割愛 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 517/4864 [00:00<00:03, 1097.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 割愛 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4867 [00:00<00:05, 851.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 割愛 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 513/4909 [00:00<00:05, 795.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 割愛 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4897 [00:00<00:05, 828.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 割愛 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 513/4674 [00:00<00:05, 804.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 割愛 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 518/4788 [00:02<00:19, 219.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 割愛 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 523/4870 [00:00<00:06, 663.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 割愛 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 517/4899 [00:00<00:06, 671.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 割愛 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 525/4835 [00:00<00:06, 675.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 割愛 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 350/350 [00:00<00:00, 1606.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 破天荒 / size: 350\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 511/580 [00:00<00:00, 1300.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 破天荒 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 511/2142 [00:00<00:01, 864.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 破天荒 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4970 [00:00<00:04, 1019.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 破天荒 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4949 [00:00<00:04, 1033.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 破天荒 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4888 [00:00<00:04, 1086.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 破天荒 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4883 [00:00<00:04, 933.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 破天荒 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 512/4677 [00:00<00:04, 982.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 破天荒 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 512/4607 [00:01<00:11, 365.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 破天荒 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4898 [00:00<00:04, 1021.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 破天荒 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 519/4934 [00:00<00:05, 855.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 破天荒 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 516/4875 [00:00<00:06, 706.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 破天荒 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 519/4921 [00:00<00:05, 804.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 破天荒 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 512/4817 [00:00<00:04, 911.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 破天荒 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:00<00:00, 1584.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 役不足 / size: 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 513/2330 [00:00<00:01, 1534.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 役不足 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 511/1507 [00:00<00:00, 1221.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 役不足 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 515/4959 [00:00<00:04, 1032.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 役不足 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 513/4960 [00:00<00:04, 1093.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 役不足 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 515/4940 [00:00<00:03, 1378.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 役不足 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 512/4934 [00:00<00:03, 1351.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 役不足 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 512/4946 [00:00<00:03, 1253.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 役不足 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4961 [00:00<00:03, 1249.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 役不足 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 512/4969 [00:00<00:03, 1186.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 役不足 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4941 [00:00<00:04, 1033.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 役不足 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 513/4933 [00:00<00:04, 891.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 役不足 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 518/4865 [00:00<00:04, 1058.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 役不足 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 516/4870 [00:00<00:04, 1036.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 役不足 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▎      | 511/1520 [00:00<00:00, 1974.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 確信犯 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▍       | 511/2082 [00:00<00:01, 1452.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 確信犯 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4978 [00:00<00:04, 1031.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 確信犯 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 511/4949 [00:00<00:04, 1027.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 確信犯 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 514/4927 [00:00<00:03, 1274.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 確信犯 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 514/4844 [00:00<00:03, 1327.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 確信犯 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 516/4884 [00:00<00:03, 1434.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 確信犯 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 512/4699 [00:00<00:03, 1376.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 確信犯 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 512/4751 [00:00<00:03, 1312.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 確信犯 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 515/4783 [00:00<00:03, 1165.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 確信犯 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 513/4916 [00:00<00:04, 1097.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 確信犯 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 514/4929 [00:00<00:03, 1273.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 確信犯 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 513/4739 [00:00<00:03, 1222.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 確信犯 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█▏        | 530/4698 [00:00<00:04, 922.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 確信犯 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 518/7138 [00:00<00:04, 1395.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 炎上 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 520/9031 [00:00<00:06, 1296.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 炎上 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 517/9944 [00:00<00:08, 1074.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 炎上 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 521/9866 [00:00<00:08, 1090.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 炎上 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 516/9709 [00:00<00:08, 1124.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 炎上 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 547/9778 [00:00<00:08, 1094.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 炎上 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 519/9685 [00:00<00:08, 1088.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 炎上 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 525/9759 [00:00<00:08, 1037.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 炎上 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 517/9659 [00:00<00:09, 952.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 炎上 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 519/9637 [00:00<00:07, 1164.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 炎上 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 513/9608 [00:00<00:09, 1009.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 炎上 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 534/9665 [00:00<00:09, 927.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 炎上 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 519/9562 [00:00<00:10, 902.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 炎上 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 525/9161 [00:00<00:08, 1004.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 炎上 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 519/4992 [00:00<00:03, 1126.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 草 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 514/8842 [00:00<00:06, 1344.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 草 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 514/9947 [00:00<00:07, 1185.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 草 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 514/9878 [00:00<00:07, 1180.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 草 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 512/9932 [00:00<00:08, 1121.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 草 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 514/9836 [00:00<00:08, 1096.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 草 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 516/9810 [00:00<00:07, 1204.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 草 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 512/9812 [00:00<00:07, 1215.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 草 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 512/9829 [00:00<00:05, 1603.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 草 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 513/9810 [00:00<00:06, 1462.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 草 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 513/9814 [00:00<00:05, 1716.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 草 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 511/9871 [00:00<00:04, 2184.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 草 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 522/9733 [00:00<00:04, 2017.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 草 / size: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 515/9600 [00:00<00:06, 1402.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start model fit\n",
            "Finish model fit: word: 草 / size: 512\n"
          ]
        }
      ],
      "source": [
        "# 初期設定群\n",
        "target = \"cl-tohoku/bert-base-japanese-whole-word-masking\"\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(target,tokenize_chinese_chars=False)\n",
        "model = BertModel.from_pretrained(target)\n",
        "\n",
        "target_words = [\n",
        "    \"失笑\",\n",
        "    \"なし崩し\",\n",
        "    \"なしくずし\",\n",
        "    \"御の字\",\n",
        "    # \"姑息\",\n",
        "    \"すべからく\",\n",
        "    \"割愛\",\n",
        "    \"破天荒\",\n",
        "    \"役不足\",\n",
        "    \"確信犯\",\n",
        "    \"炎上\",\n",
        "    \"草\",\n",
        "]\n",
        "with open(\"Japanese.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  stop_words = set([w.strip() for w in f] + [\"する\", \"なる\", \"いる\", \"ある\"])\n",
        "\n",
        "data_dir = \"twitter-corpus\"\n",
        "path_list = glob.glob(data_dir + \"/*.json\")\n",
        "path_list.sort()\n",
        "# ターゲットとする単語や期間の整理は予めここで行う\n",
        "oparation = [\n",
        "    {\n",
        "        \"word\": w,\n",
        "        \"year\": y,\n",
        "        \"path_list\": list(filter(lambda x: w in x and str(y) in x, path_list)),\n",
        "    }\n",
        "    for w in target_words\n",
        "    for y in range(2007, 2021)\n",
        "]\n",
        "for o in oparation:\n",
        "    if not len(o[\"path_list\"]):\n",
        "        continue\n",
        "    output_path = \"word-vectors/\" + o[\"word\"] + \"-\" + str(o[\"year\"]) + \".dict\"\n",
        "    corpus = prepareCorpus(o[\"path_list\"])\n",
        "    get_usage(\n",
        "        text_list=corpus[\"preprocessedText\"].values.tolist(),\n",
        "        target_word=o[\"word\"],\n",
        "        output_path=output_path,\n",
        "        sequence_length=256,\n",
        "        buffer_size=512,\n",
        "        layer_range=(1, 14),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/word-vectors.zip /content/word-vectors\n",
        "from google.colab import files\n",
        "files.download(\"/content/word-vectors.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UszbavMrthde",
        "outputId": "4f1c6038-50b2-4974-95db-10157f2434e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/word-vectors/ (stored 0%)\n",
            "  adding: content/word-vectors/すべからく-2010.dict (deflated 29%)\n",
            "  adding: content/word-vectors/なし崩し-2018.dict (deflated 48%)\n",
            "  adding: content/word-vectors/確信犯-2018.dict (deflated 76%)\n",
            "  adding: content/word-vectors/役不足-2007.dict (deflated 21%)\n",
            "  adding: content/word-vectors/御の字-2015.dict (deflated 25%)\n",
            "  adding: content/word-vectors/すべからく-2018.dict (deflated 41%)\n",
            "  adding: content/word-vectors/御の字-2011.dict (deflated 24%)\n",
            "  adding: content/word-vectors/なし崩し-2008.dict (deflated 21%)\n",
            "  adding: content/word-vectors/炎上-2014.dict (deflated 31%)\n",
            "  adding: content/word-vectors/失笑-2009.dict (deflated 23%)\n",
            "  adding: content/word-vectors/役不足-2013.dict (deflated 27%)\n",
            "  adding: content/word-vectors/失笑-2017.dict (deflated 25%)\n",
            "  adding: content/word-vectors/確信犯-2008.dict (deflated 23%)\n",
            "  adding: content/word-vectors/なしくずし-2019.dict (deflated 47%)\n",
            "  adding: content/word-vectors/失笑-2011.dict (deflated 25%)\n",
            "  adding: content/word-vectors/割愛-2017.dict (deflated 29%)\n",
            "  adding: content/word-vectors/炎上-2010.dict (deflated 25%)\n",
            "  adding: content/word-vectors/割愛-2010.dict (deflated 34%)\n",
            "  adding: content/word-vectors/破天荒-2012.dict (deflated 33%)\n",
            "  adding: content/word-vectors/炎上-2018.dict (deflated 54%)\n",
            "  adding: content/word-vectors/なしくずし-2012.dict (deflated 68%)\n",
            "  adding: content/word-vectors/なし崩し-2009.dict (deflated 24%)\n",
            "  adding: content/word-vectors/破天荒-2017.dict (deflated 41%)\n",
            "  adding: content/word-vectors/炎上-2019.dict (deflated 30%)\n",
            "  adding: content/word-vectors/破天荒-2011.dict (deflated 27%)\n",
            "  adding: content/word-vectors/御の字-2016.dict (deflated 24%)\n",
            "  adding: content/word-vectors/なしくずし-2014.dict (deflated 30%)\n",
            "  adding: content/word-vectors/すべからく-2011.dict (deflated 30%)\n",
            "  adding: content/word-vectors/破天荒-2010.dict (deflated 24%)\n",
            "  adding: content/word-vectors/破天荒-2008.dict (deflated 24%)\n",
            "  adding: content/word-vectors/なし崩し-2014.dict (deflated 37%)\n",
            "  adding: content/word-vectors/役不足-2009.dict (deflated 29%)\n",
            "  adding: content/word-vectors/失笑-2010.dict (deflated 23%)\n",
            "  adding: content/word-vectors/確信犯-2007.dict (deflated 21%)\n",
            "  adding: content/word-vectors/なしくずし-2020.dict (deflated 33%)\n",
            "  adding: content/word-vectors/なし崩し-2016.dict (deflated 45%)\n",
            "  adding: content/word-vectors/割愛-2011.dict (deflated 25%)\n",
            "  adding: content/word-vectors/破天荒-2014.dict (deflated 29%)\n",
            "  adding: content/word-vectors/破天荒-2007.dict (deflated 26%)\n",
            "  adding: content/word-vectors/御の字-2012.dict (deflated 25%)\n",
            "  adding: content/word-vectors/なしくずし-2009.dict (deflated 22%)\n",
            "  adding: content/word-vectors/確信犯-2015.dict (deflated 26%)\n",
            "  adding: content/word-vectors/確信犯-2014.dict (deflated 27%)\n",
            "  adding: content/word-vectors/破天荒-2018.dict (deflated 29%)\n",
            "  adding: content/word-vectors/役不足-2018.dict (deflated 34%)\n",
            "  adding: content/word-vectors/割愛-2019.dict (deflated 29%)\n",
            "  adding: content/word-vectors/なし崩し-2020.dict (deflated 36%)\n",
            "  adding: content/word-vectors/なしくずし-2018.dict (deflated 67%)\n",
            "  adding: content/word-vectors/草-2020.dict (deflated 25%)\n",
            "  adding: content/word-vectors/御の字-2007.dict (deflated 21%)\n",
            "  adding: content/word-vectors/役不足-2015.dict (deflated 34%)\n",
            "  adding: content/word-vectors/失笑-2015.dict (deflated 32%)\n",
            "  adding: content/word-vectors/破天荒-2015.dict (deflated 30%)\n",
            "  adding: content/word-vectors/破天荒-2009.dict (deflated 25%)\n",
            "  adding: content/word-vectors/破天荒-2020.dict (deflated 37%)\n",
            "  adding: content/word-vectors/すべからく-2014.dict (deflated 37%)\n",
            "  adding: content/word-vectors/草-2014.dict (deflated 25%)\n",
            "  adding: content/word-vectors/炎上-2009.dict (deflated 24%)\n",
            "  adding: content/word-vectors/役不足-2020.dict (deflated 30%)\n",
            "  adding: content/word-vectors/草-2013.dict (deflated 25%)\n",
            "  adding: content/word-vectors/なしくずし-2008.dict (deflated 21%)\n",
            "  adding: content/word-vectors/なし崩し-2017.dict (deflated 54%)\n",
            "  adding: content/word-vectors/割愛-2018.dict (deflated 28%)\n",
            "  adding: content/word-vectors/なし崩し-2007.dict (deflated 21%)\n",
            "  adding: content/word-vectors/すべからく-2017.dict (deflated 35%)\n",
            "  adding: content/word-vectors/草-2007.dict (deflated 28%)\n",
            "  adding: content/word-vectors/なしくずし-2010.dict (deflated 27%)\n",
            "  adding: content/word-vectors/割愛-2007.dict (deflated 21%)\n",
            "  adding: content/word-vectors/なしくずし-2011.dict (deflated 42%)\n",
            "  adding: content/word-vectors/割愛-2008.dict (deflated 22%)\n",
            "  adding: content/word-vectors/なしくずし-2016.dict (deflated 46%)\n",
            "  adding: content/word-vectors/失笑-2008.dict (deflated 23%)\n",
            "  adding: content/word-vectors/御の字-2014.dict (deflated 26%)\n",
            "  adding: content/word-vectors/割愛-2016.dict (deflated 40%)\n",
            "  adding: content/word-vectors/失笑-2013.dict (deflated 38%)\n",
            "  adding: content/word-vectors/なし崩し-2013.dict (deflated 66%)\n",
            "  adding: content/word-vectors/失笑-2012.dict (deflated 31%)\n",
            "  adding: content/word-vectors/御の字-2010.dict (deflated 23%)\n",
            "  adding: content/word-vectors/役不足-2008.dict (deflated 53%)\n",
            "  adding: content/word-vectors/割愛-2013.dict (deflated 27%)\n",
            "  adding: content/word-vectors/確信犯-2016.dict (deflated 27%)\n",
            "  adding: content/word-vectors/御の字-2013.dict (deflated 26%)\n",
            "  adding: content/word-vectors/草-2016.dict (deflated 29%)\n",
            "  adding: content/word-vectors/破天荒-2019.dict (deflated 36%)\n",
            "  adding: content/word-vectors/すべからく-2016.dict (deflated 35%)\n",
            "  adding: content/word-vectors/確信犯-2012.dict (deflated 25%)\n",
            "  adding: content/word-vectors/確信犯-2020.dict (deflated 29%)\n",
            "  adding: content/word-vectors/役不足-2014.dict (deflated 26%)\n",
            "  adding: content/word-vectors/御の字-2020.dict (deflated 23%)\n",
            "  adding: content/word-vectors/炎上-2013.dict (deflated 30%)\n",
            "  adding: content/word-vectors/草-2008.dict (deflated 24%)\n",
            "  adding: content/word-vectors/役不足-2016.dict (deflated 33%)\n",
            "  adding: content/word-vectors/失笑-2019.dict (deflated 64%)\n",
            "  adding: content/word-vectors/割愛-2012.dict (deflated 26%)\n",
            "  adding: content/word-vectors/なし崩し-2011.dict (deflated 38%)\n",
            "  adding: content/word-vectors/御の字-2017.dict (deflated 27%)\n",
            "  adding: content/word-vectors/すべからく-2008.dict (deflated 22%)\n",
            "  adding: content/word-vectors/草-2011.dict (deflated 23%)\n",
            "  adding: content/word-vectors/なし崩し-2010.dict (deflated 28%)\n",
            "  adding: content/word-vectors/失笑-2016.dict (deflated 31%)\n",
            "  adding: content/word-vectors/失笑-2020.dict (deflated 37%)\n",
            "  adding: content/word-vectors/確信犯-2019.dict (deflated 63%)\n",
            "  adding: content/word-vectors/割愛-2015.dict (deflated 30%)\n",
            "  adding: content/word-vectors/草-2019.dict (deflated 38%)\n",
            "  adding: content/word-vectors/確信犯-2010.dict (deflated 30%)\n",
            "  adding: content/word-vectors/炎上-2016.dict (deflated 45%)\n",
            "  adding: content/word-vectors/炎上-2015.dict (deflated 29%)\n",
            "  adding: content/word-vectors/御の字-2008.dict (deflated 22%)\n",
            "  adding: content/word-vectors/すべからく-2012.dict (deflated 32%)\n",
            "  adding: content/word-vectors/すべからく-2009.dict (deflated 25%)\n",
            "  adding: content/word-vectors/確信犯-2013.dict (deflated 26%)\n",
            "  adding: content/word-vectors/なし崩し-2012.dict (deflated 37%)\n",
            "  adding: content/word-vectors/なしくずし-2013.dict (deflated 46%)\n",
            "  adding: content/word-vectors/草-2017.dict (deflated 28%)\n",
            "  adding: content/word-vectors/確信犯-2011.dict (deflated 33%)\n",
            "  adding: content/word-vectors/炎上-2012.dict (deflated 30%)\n",
            "  adding: content/word-vectors/炎上-2011.dict (deflated 27%)\n",
            "  adding: content/word-vectors/失笑-2014.dict (deflated 37%)\n",
            "  adding: content/word-vectors/役不足-2019.dict (deflated 56%)\n",
            "  adding: content/word-vectors/なしくずし-2017.dict (deflated 89%)\n",
            "  adding: content/word-vectors/確信犯-2009.dict (deflated 23%)\n",
            "  adding: content/word-vectors/草-2018.dict (deflated 60%)\n",
            "  adding: content/word-vectors/確信犯-2017.dict (deflated 30%)\n",
            "  adding: content/word-vectors/すべからく-2020.dict (deflated 44%)\n",
            "  adding: content/word-vectors/なし崩し-2019.dict (deflated 49%)\n",
            "  adding: content/word-vectors/すべからく-2007.dict (deflated 21%)\n",
            "  adding: content/word-vectors/草-2012.dict (deflated 23%)\n",
            "  adding: content/word-vectors/割愛-2020.dict (deflated 27%)\n",
            "  adding: content/word-vectors/割愛-2014.dict (deflated 27%)\n",
            "  adding: content/word-vectors/失笑-2018.dict (deflated 28%)\n",
            "  adding: content/word-vectors/なしくずし-2015.dict (deflated 40%)\n",
            "  adding: content/word-vectors/炎上-2007.dict (deflated 29%)\n",
            "  adding: content/word-vectors/御の字-2019.dict (deflated 24%)\n",
            "  adding: content/word-vectors/すべからく-2013.dict (deflated 35%)\n",
            "  adding: content/word-vectors/炎上-2017.dict (deflated 38%)\n",
            "  adding: content/word-vectors/御の字-2018.dict (deflated 24%)\n",
            "  adding: content/word-vectors/役不足-2011.dict (deflated 27%)\n",
            "  adding: content/word-vectors/炎上-2008.dict (deflated 24%)\n",
            "  adding: content/word-vectors/御の字-2009.dict (deflated 23%)\n",
            "  adding: content/word-vectors/草-2015.dict (deflated 26%)\n",
            "  adding: content/word-vectors/役不足-2010.dict (deflated 24%)\n",
            "  adding: content/word-vectors/役不足-2017.dict (deflated 28%)\n",
            "  adding: content/word-vectors/草-2009.dict (deflated 22%)\n",
            "  adding: content/word-vectors/破天荒-2013.dict (deflated 30%)\n",
            "  adding: content/word-vectors/すべからく-2015.dict (deflated 35%)\n",
            "  adding: content/word-vectors/なしくずし-2007.dict (deflated 91%)\n",
            "  adding: content/word-vectors/すべからく-2019.dict (deflated 34%)\n",
            "  adding: content/word-vectors/草-2010.dict (deflated 27%)\n",
            "  adding: content/word-vectors/破天荒-2016.dict (deflated 50%)\n",
            "  adding: content/word-vectors/割愛-2009.dict (deflated 23%)\n",
            "  adding: content/word-vectors/なし崩し-2015.dict (deflated 34%)\n",
            "  adding: content/word-vectors/役不足-2012.dict (deflated 24%)\n",
            "  adding: content/word-vectors/炎上-2020.dict (deflated 36%)\n",
            "  adding: content/word-vectors/失笑-2007.dict (deflated 23%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_62fbc56d-f854-436a-894d-8e0b758452b4\", \"word-vectors.zip\", 197965053)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMFDUpCjRS6k8jYu+TME+8R"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}