{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWh0CjbzvOYamLWmtaZ65g"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- なし崩し\n",
        "- 失笑\n",
        "- 御の字\n",
        "- 姑息\n",
        "- すべからく\n",
        "- 割愛\n",
        "- 破天荒\n",
        "- 役不足\n",
        "- 確信犯\n",
        "\n"
      ],
      "metadata": {
        "id": "WxrjGqfnt-Pe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZRr8uBOlzj0R"
      },
      "outputs": [],
      "source": [
        "# For sending GET requests from the API\n",
        "import requests\n",
        "# For saving access tokens and for file management when creating and adding to the dataset\n",
        "import os\n",
        "# For dealing with json responses we receive from the API\n",
        "import json\n",
        "#To add wait time between requests\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Global settings\n",
        "\n",
        "target_url = \"https://api.twitter.com/2/tweets/search/all\" #Change to the endpoint you want to collect data from\n",
        "\n",
        "with open(\"response_count.json\", \"w\", encoding='utf-8') as f:\n",
        "  json.dump({\"meta\":{\"words\":[]}}, f, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "44njLW2ApneK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_header():\n",
        "  return {\"Authorization\": \"Bearer {}\".format(os.getenv(\"TOKEN\"))}\n",
        "\n",
        "def create_params(keyword, start_time, end_time, max_results = 10, next_token = None):\n",
        "  #change params based on the endpoint you are using\n",
        "  return {'query': keyword,\n",
        "          'start_time': start_time,\n",
        "          'end_time': end_time,\n",
        "          'max_results': max_results,\n",
        "          'expansions': '',\n",
        "          'tweet.fields': 'id,text,created_at',\n",
        "          'next_token': next_token}\n",
        "\n",
        "def request_to_endpoint(url, headers, params):\n",
        "  response = requests.request(\"GET\", url, headers=headers, params=params)\n",
        "  time.sleep(1)\n",
        "  # print(\"Endpoint Response Code: \" + str(response.status_code))\n",
        "  if response.status_code != 200:\n",
        "      raise Exception(response.status_code, response.text)\n",
        "  return response.json()\n",
        "\n",
        "def fetchTweet(keyword, start_time, end_time):\n",
        "  rest = int(max_results)\n",
        "  response = {\"data\": [], \"size\": 0}\n",
        "  next_token = None\n",
        "  while rest > 0:\n",
        "    res = request_to_endpoint(url=target_url, headers=create_header(), params=create_params(keyword, start_time, end_time, max_results=500, next_token=next_token))\n",
        "    rest -= 500\n",
        "    if \"meta\" in res:\n",
        "      response[\"size\"] += int(res['meta']['result_count'])\n",
        "      if \"next_token\" in res[\"meta\"]:\n",
        "        next_token = res[\"meta\"][\"next_token\"]\n",
        "    if \"data\" in res:\n",
        "      response[\"data\"].extend(res[\"data\"])\n",
        "  return response\n"
      ],
      "metadata": {
        "id": "4TreYIa3pnnK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 単一キーワード取得\n",
        "keyword = \"失笑\"\n",
        "year=2014\n",
        "max_results = 10000\n",
        "\n",
        "word = keyword + \" lang:ja\"\n",
        "start_time = str(year)+\"-01-01T00:00:00.000Z\"\n",
        "end_time = str(year)+\"-12-31T00:00:00.000Z\"\n",
        "with open(\"{}.json\".format('only-'+str(keyword)+'-'+str(year)), \"w\", encoding='utf-8') as f:\n",
        "  json.dump(fetchTweet(word, start_time, end_time), f, ensure_ascii=False)\n"
      ],
      "metadata": {
        "id": "15dZvnAZw-9B"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 複数キーワード取得\n",
        "keywords = [\"失笑\",\"なし崩し\",\"なしくずし\",\"御の字\",\"姑息\",\"すべからく\",\"割愛\",\"破天荒\",\"役不足\",\"確信犯\"]\n",
        "years = list(range(2007,2021))\n",
        "max_results = 5000\n",
        "\n",
        "\n",
        "for k in keywords:\n",
        "  word = k + \" lang:ja\"\n",
        "  for y in years:\n",
        "    with open(\"response_count.json\") as response_count_json:\n",
        "      response_count = json.load(response_count_json)\n",
        "      if str(k) in response_count and str(y) in response_count[str(k)]: continue; pass\n",
        "      start_time = str(y)+\"-01-01T00:00:00.000Z\"\n",
        "      end_time = str(y)+\"-12-31T00:00:00.000Z\"\n",
        "      response = fetchTweet(word, start_time, end_time)\n",
        "      if str(k) in response_count:\n",
        "        response_count[str(k)][str(y)]= response[\"size\"]\n",
        "      else:\n",
        "        response_count['meta']['words'].append(str(k))\n",
        "        response_count[str(k)] = {str(y): response[\"size\"]}\n",
        "      with open(\"response_count.json\", \"w\", encoding='utf-8') as f:\n",
        "        json.dump(response_count, f, ensure_ascii=False)\n",
        "      with open(\"{}.json\".format(str(k)+'-'+str(y)), \"w\", encoding='utf-8') as f:\n",
        "        json.dump(response, f, ensure_ascii=False)\n",
        "      print('fetch finish:'+str(k)+':'+str(y))"
      ],
      "metadata": {
        "id": "WfcTJsZXpvWK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}